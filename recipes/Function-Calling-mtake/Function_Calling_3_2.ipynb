{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement function calling with the Granite-3-8B-Instruct model in Python with WatsonX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Authors:** Erika Russi, Anna Gutowska, Jess Bozorg\n",
    "\n",
    "In this tutorial, you will use the IBM® [Granite-3-8B-Instruct model](https://www.ibm.com/granite) now available on watsonx.ai™ to perform custom function calling.  \n",
    "\n",
    "Traditional [large language models (LLMs)](https://www.ibm.com/topics/large-language-models), like the OpenAI GPT-4 (generative pre-trained transformer) model available through ChatGPT, and the IBM Granite™ models that we'll use in this tutorial, are limited in their knowledge and reasoning. They produce their responses based on the data used to train them and are difficult to adapt to personalized user queries. To obtain the missing information, these [generative AI](https://www.ibm.com/topics/generative-ai) models can integrate external tools within the function calling. This method is one way to avoid fine-tuning a foundation model for each specific use-case. The function calling examples in this tutorial will implement external [API](https://www.ibm.com/topics/api) calls. \n",
    "\n",
    "The Granite-3-8B-Instruct model and tokenizer use [natural language processing (NLP)](https://www.ibm.com/topics/natural-language-processing) to parse query syntax. In addition, the models use function descriptions and function parameters to determine the appropriate tool calls. Key information is then extracted from user queries to be passed as function arguments. \n",
    "\n",
    "[![Open YouTube video](https://img.youtube.com/vi/cjCYcTPryw8/0.jpg)](https://www.youtube.com/watch?v=cjCYcTPryw8)\n",
    "\n",
    "This recipe is also available on [IBM.com](https://www.ibm.com/think/tutorials/granite-function-calling).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Set up your environment\n",
    "\n",
    "While you can choose from several tools, this tutorial is best suited for a Jupyter Notebook. Jupyter Notebooks are widely used within data science to combine code with various data sources such as text, images and data visualizations. \n",
    "\n",
    "You can run this notebook in [Colab](https://colab.research.google.com/), or download it to your system and [run the notebook locally](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started_with_Jupyter_Locally/Getting_Started_with_Jupyter_Locally.md). \n",
    "\n",
    "To avoid Python package dependency conflicts, we recommend setting up a [virtual environment](https://docs.python.org/3/library/venv.html).  \n",
    "\n",
    "Note, this notebook is compatible with Python 3.11.10 and well as Python 3.10.12, the default in Colab at the time of publishing this tutorial. To check your python version, you can run the `!python --version` command in a code cell.\n",
    "\n",
    "## Step 2. Set up a Watson Machine Learning service instance and API key\n",
    "\n",
    "Walk through the [Getting Started with IBM WatsonX](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started/Getting_Started_with_WatsonX.ipynb) recipe to ensure you can connect to WatsonX.\n",
    "\n",
    "## Step 3. Install and import relevant libraries and set up your credentials\n",
    "\n",
    "We'll need a few libraries and modules for this tutorial. Make sure to import the following ones; if they're not installed, you can resolve this with a quick pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installations\n",
    "%pip install -q git+https://github.com/ibm-granite-community/utils \\\n",
    "    langchain-ibm \\\n",
    "    transformers \\\n",
    "    Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mtake/.pyenv/versions/3.11.8/envs/granite-snack-cookbook-py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import requests\n",
    "import ast\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can prepare our environment by setting the model ID for the `granite-3-8b-instruct` model, and the tokenizer for the same Granite model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"ibm/granite-3-2-8b-instruct\"\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(\"ibm-granite/granite-3.2-8b-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_stock_price` function in this tutorial requires an `AV_STOCK_API_KEY` key. To generate a free `AV_STOCK_API_KEY`, please visit the [Alpha Vantage website](https://www.alphavantage.co/support/#api-key). \n",
    "\n",
    "Secondly, the `get_current_weather` function requires a `WEATHER_API_KEY`. To generate one, please [create an account](https://home.openweathermap.org/users/sign_up). Upon creating an account, select the \"API Keys\" tab to display your free key.\n",
    "\n",
    "**Store these private keys in a separate `.env` file in the same level of your directory as this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "AV_STOCK_API_KEY = get_env_var(\"AV_STOCK_API_KEY\", \"none\")\n",
    "\n",
    "WEATHER_API_KEY = get_env_var(\"WEATHER_API_KEY\", \"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Define the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define our functions. The function's docstring and type information are important for generating the proper tool information.\n",
    "\n",
    "In this tutorial, the `get_stock_price` function uses the Stock Market Data API available through Alpha Vantage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(ticker: str, date: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves the lowest and highest stock prices for a given ticker and date.\n",
    "\n",
    "    Args:\n",
    "        ticker: The stock ticker symbol, e.g., \"IBM\".\n",
    "        date: The date in \"YYYY-MM-DD\" format for which you want to get stock prices.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the low and high stock prices on the given date.\n",
    "    \"\"\"\n",
    "    print(f\"Getting stock price for {ticker} on {date}\")\n",
    "    try:\n",
    "        stock_url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&apikey={AV_STOCK_API_KEY}\"\n",
    "        stock_data = requests.get(stock_url)\n",
    "        stock_low = stock_data.json()[\"Time Series (Daily)\"][date][\"3. low\"]\n",
    "        stock_high = stock_data.json()[\"Time Series (Daily)\"][date][\"2. high\"]\n",
    "        return {\n",
    "            \"low\": stock_low,\n",
    "            \"high\": stock_high\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching stock data: {e}\")\n",
    "        return {\n",
    "            \"low\": \"none\",\n",
    "            \"high\": \"none\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price_ja(ticker: str, date: str) -> dict:\n",
    "    \"\"\"\n",
    "    指定されたティッカーと日付の最安値と最高値を取得します。\n",
    "\n",
    "    Args:\n",
    "        ticker: 株券のティッカーシンボル、例えば 「IBM」。\n",
    "        date: 株価を取得したい日付を「YYYY-MM-DD」形式で指定します。\n",
    "\n",
    "    Returns:\n",
    "        指定された日付の株価の安値と高値を含む辞書。\n",
    "    \"\"\"\n",
    "    print(f\"Getting stock price for {ticker} on {date}\")\n",
    "    try:\n",
    "        stock_url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&apikey={AV_STOCK_API_KEY}\"\n",
    "        stock_data = requests.get(stock_url)\n",
    "        stock_low = stock_data.json()[\"Time Series (Daily)\"][date][\"3. low\"]\n",
    "        stock_high = stock_data.json()[\"Time Series (Daily)\"][date][\"2. high\"]\n",
    "        return {\n",
    "            \"low\": stock_low,\n",
    "            \"high\": stock_high\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching stock data: {e}\")\n",
    "        return {\n",
    "            \"low\": \"none\",\n",
    "            \"high\": \"none\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_current_weather` function retrieves the real-time weather in a given location using the Current Weather Data API via [OpenWeather](https://openweathermap.org/api). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches the current weather for a given location (default: San Francisco).\n",
    "\n",
    "    Args:\n",
    "        location: The name of the city for which to retrieve the weather information.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing weather information such as temperature, weather description, and humidity.\n",
    "    \"\"\"\n",
    "    print(f\"Getting current weather for {location}\")\n",
    "\n",
    "    try:\n",
    "        # API request to fetch weather data\n",
    "        weather_url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={WEATHER_API_KEY}&units=metric\"\n",
    "        weather_data = requests.get(weather_url)\n",
    "        data = weather_data.json()\n",
    "        # Extracting relevant weather details\n",
    "        weather_description = data[\"weather\"][0][\"description\"]\n",
    "        temperature = data[\"main\"][\"temp\"]\n",
    "        humidity = data[\"main\"][\"humidity\"]\n",
    "\n",
    "        # Returning weather details\n",
    "        return {\n",
    "            \"description\": weather_description,\n",
    "            \"temperature\": temperature,\n",
    "            \"humidity\": humidity\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return {\n",
    "            \"description\": \"none\",\n",
    "            \"temperature\": \"none\",\n",
    "            \"humidity\": \"none\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather_ja(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    指定した場所（デフォルト：サンフランシスコ）の現在の天気を取得します。\n",
    "\n",
    "    Args:\n",
    "        location: 気象情報を取得する都市名。\n",
    "\n",
    "    Returns:\n",
    "        気温、天気予報、湿度などの気象情報を含む辞書。\n",
    "    \"\"\"\n",
    "    print(f\"Getting current weather for {location}\")\n",
    "\n",
    "    try:\n",
    "        # API request to fetch weather data\n",
    "        weather_url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={WEATHER_API_KEY}&units=metric\"\n",
    "        weather_data = requests.get(weather_url)\n",
    "        data = weather_data.json()\n",
    "        # Extracting relevant weather details\n",
    "        weather_description = data[\"weather\"][0][\"description\"]\n",
    "        temperature = data[\"main\"][\"temp\"]\n",
    "        humidity = data[\"main\"][\"humidity\"]\n",
    "\n",
    "        # Returning weather details\n",
    "        return {\n",
    "            \"description\": weather_description,\n",
    "            \"temperature\": temperature,\n",
    "            \"humidity\": humidity\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return {\n",
    "            \"description\": \"none\",\n",
    "            \"temperature\": \"none\",\n",
    "            \"humidity\": \"none\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Set up the API request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our functions are defined, we can create a function that generates a watsonx API request for the provided instructions the watsonx API endpoint. We will use this function each time we make a request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "def make_api_request(instructions: str) -> str:\n",
    "    model_parameters = {\n",
    "        \"decoding_method\": \"greedy\",\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"repetition_penalty\": 1.05,\n",
    "        \"stop_sequences\": [TOKENIZER.eos_token]\n",
    "    }\n",
    "    model = WatsonxLLM(\n",
    "        model_id=MODEL_ID,\n",
    "        url= get_env_var(\"WATSONX_URL\"),\n",
    "        apikey=get_env_var(\"WATSONX_APIKEY\"),\n",
    "        project_id=get_env_var(\"WATSONX_PROJECT_ID\"),\n",
    "        params=model_parameters\n",
    "    )\n",
    "    response = model.invoke(instructions)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create a list of available functions. Here, we declare our function definitions that require the function names, descriptions, parameters and required properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_stock_price',\n",
       "  'description': 'Retrieves the lowest and highest stock prices for a given ticker and date.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'ticker': {'type': 'string',\n",
       "     'description': 'The stock ticker symbol, e.g., \"IBM\".'},\n",
       "    'date': {'type': 'string',\n",
       "     'description': 'The date in \"YYYY-MM-DD\" format for which you want to get stock prices.'}},\n",
       "   'required': ['ticker', 'date']},\n",
       "  'return': {'type': 'object',\n",
       "   'description': 'A dictionary containing the low and high stock prices on the given date.'}},\n",
       " {'name': 'get_current_weather',\n",
       "  'description': 'Fetches the current weather for a given location (default: San Francisco).',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'location': {'type': 'string',\n",
       "     'description': 'The name of the city for which to retrieve the weather information.'}},\n",
       "   'required': ['location']},\n",
       "  'return': {'type': 'object',\n",
       "   'description': 'A dictionary containing weather information such as temperature, weather description, and humidity.'}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import get_json_schema\n",
    "\n",
    "tools = [get_json_schema(tool)[\"function\"] for tool in (get_stock_price, get_current_weather)]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_stock_price_ja',\n",
       "  'description': '指定されたティッカーと日付の最安値と最高値を取得します。',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'ticker': {'type': 'string',\n",
       "     'description': '株券のティッカーシンボル、例えば 「IBM」。'},\n",
       "    'date': {'type': 'string',\n",
       "     'description': '株価を取得したい日付を「YYYY-MM-DD」形式で指定します。'}},\n",
       "   'required': ['ticker', 'date']},\n",
       "  'return': {'type': 'object', 'description': '指定された日付の株価の安値と高値を含む辞書。'}},\n",
       " {'name': 'get_current_weather_ja',\n",
       "  'description': '指定した場所（デフォルト：サンフランシスコ）の現在の天気を取得します。',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'location': {'type': 'string',\n",
       "     'description': '気象情報を取得する都市名。'}},\n",
       "   'required': ['location']},\n",
       "  'return': {'type': 'object', 'description': '気温、天気予報、湿度などの気象情報を含む辞書。'}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import get_json_schema\n",
    "\n",
    "tools_ja = [get_json_schema(tool)[\"function\"] for tool in (get_stock_price_ja, get_current_weather_ja)]\n",
    "tools_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Perform function calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6a. Calling the get_stock_price function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for the API requests, we must set our `query` used in the tokenizer chat template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What were the IBM stock prices on March 7, 2025?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ja = \"2025年3月7日のIBMの株価は？\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a chat template is useful for breaking up long strings of texts into one or more messages with corresponding labels. This allows the LLM to process the input in a format that it expects. Because we want our output to be in a string format, we can set the `tokenize` parameter to false. The `add_generation_prompt` can be set to true in order to append the tokens indicating the beginning of an assistant message to the output. This will be useful when generating chat completions with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_of_role|>system<|end_of_role|>You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.<|end_of_text|>\\n<|start_of_role|>tools<|end_of_role|>[\\n    {\\n        \"name\": \"get_stock_price\",\\n        \"description\": \"Retrieves the lowest and highest stock prices for a given ticker and date.\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"ticker\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"The stock ticker symbol, e.g., \\\\\"IBM\\\\\".\"\\n                },\\n                \"date\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"The date in \\\\\"YYYY-MM-DD\\\\\" format for which you want to get stock prices.\"\\n                }\\n            },\\n            \"required\": [\\n                \"ticker\",\\n                \"date\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"A dictionary containing the low and high stock prices on the given date.\"\\n        }\\n    },\\n    {\\n        \"name\": \"get_current_weather\",\\n        \"description\": \"Fetches the current weather for a given location (default: San Francisco).\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"location\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"The name of the city for which to retrieve the weather information.\"\\n                }\\n            },\\n            \"required\": [\\n                \"location\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"A dictionary containing weather information such as temperature, weather description, and humidity.\"\\n        }\\n    }\\n]<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>What were the IBM stock prices on March 7, 2025?<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"system\",\"content\": \"You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.\"},\n",
    "    {\"role\": \"user\", \"content\": query },\n",
    "]\n",
    "\n",
    "instruction_1 = TOKENIZER.apply_chat_template(conversation=conversation, tools=tools, tokenize=False, add_generation_prompt=True)\n",
    "instruction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_of_role|>system<|end_of_role|>You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.<|end_of_text|>\\n<|start_of_role|>tools<|end_of_role|>[\\n    {\\n        \"name\": \"get_stock_price_ja\",\\n        \"description\": \"指定されたティッカーと日付の最安値と最高値を取得します。\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"ticker\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"株券のティッカーシンボル、例えば 「IBM」。\"\\n                },\\n                \"date\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"株価を取得したい日付を「YYYY-MM-DD」形式で指定します。\"\\n                }\\n            },\\n            \"required\": [\\n                \"ticker\",\\n                \"date\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"指定された日付の株価の安値と高値を含む辞書。\"\\n        }\\n    },\\n    {\\n        \"name\": \"get_current_weather_ja\",\\n        \"description\": \"指定した場所（デフォルト：サンフランシスコ）の現在の天気を取得します。\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"location\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"気象情報を取得する都市名。\"\\n                }\\n            },\\n            \"required\": [\\n                \"location\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"気温、天気予報、湿度などの気象情報を含む辞書。\"\\n        }\\n    }\\n]<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>2025年3月7日のIBMの株価は？<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_ja = [\n",
    "    {\"role\": \"system\",\"content\": \"You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.\"},\n",
    "    {\"role\": \"user\", \"content\": query_ja },\n",
    "]\n",
    "\n",
    "instruction_1_ja = TOKENIZER.apply_chat_template(conversation=conversation_ja, tools=tools_ja, tokenize=False, add_generation_prompt=True)\n",
    "instruction_1_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call the `make_api_request` function and pass the instructions we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tool_call>[{\"name\": \"get_stock_price\", \"arguments\": {\"ticker\": \"IBM\", \"date\": \"2025-03-07\"}}]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = make_api_request(instruction_1)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tool_call>[{\"name\": \"get_stock_price_ja\", \"arguments\": {\"ticker\": \"IBM\", \"date\": \"2025-03-07\"}}]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_ja = make_api_request(instruction_1_ja)\n",
    "data_1_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by the function name in the JSON object produced by the model, the appropriate `get_stock_price` tool use was selected from the set of functions. To run the function, let's extract relevant information from the output. With the function name and arguments extracted, we can call the function. To call the function using its name as a string, we can use the `globals()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_call(llm_response: str):\n",
    "    tool_request = ast.literal_eval(re.search(\"({.+})\", llm_response).group(0))\n",
    "    tool_name = tool_request[\"name\"]\n",
    "    tool_arguments = tool_request[\"arguments\"]\n",
    "    tool_response = globals()[tool_name](**tool_arguments)\n",
    "    return tool_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the response from the requested tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting stock price for IBM on 2025-03-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'low': '245.1823', 'high': '261.9600'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response = tool_call(data_1)\n",
    "tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting stock price for IBM on 2025-03-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'low': '245.1823', 'high': '261.9600'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response_ja = tool_call(data_1_ja)\n",
    "tool_response_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function successfully retrieved the requested stock price. To generate a synthesized final response, we can pass another prompt to the Granite model along with the information collected from function calling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On March 7, 2025, the lowest IBM stock price was $245.18 and the highest was $261.96.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2 = conversation + [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Display the tool response in natural language.\" },\n",
    "    {\"role\": \"tool_response\", \"content\": str(tool_response) },\n",
    "]\n",
    "\n",
    "instruction_2 = TOKENIZER.apply_chat_template(conversation=conversation2, tools=tools, tokenize=False, add_generation_prompt=True)\n",
    "data_2 = make_api_request(instruction_2)\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBMの株価は2025年3月7日の最安値は245.1823ドル、最高値は261.9600ドルでした。'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2_ja = conversation_ja + [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Display the tool response in natural language.\" },\n",
    "    {\"role\": \"tool_response\", \"content\": str(tool_response_ja) },\n",
    "]\n",
    "\n",
    "instruction_2_ja = TOKENIZER.apply_chat_template(conversation=conversation2_ja, tools=tools_ja, tokenize=False, add_generation_prompt=True)\n",
    "data_2_ja = make_api_request(instruction_2_ja)\n",
    "data_2_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6b. Calling the get_current_weather function\n",
    "\n",
    "As our next query, let’s inquire about the current weather in San Francisco. We can follow the same steps as in Step 5a by adjusting the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the current weather in San Francisco?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ja = \"サンフランシスコの現在の天気は？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_of_role|>system<|end_of_role|>You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.<|end_of_text|>\\n<|start_of_role|>tools<|end_of_role|>[\\n    {\\n        \"name\": \"get_stock_price\",\\n        \"description\": \"Retrieves the lowest and highest stock prices for a given ticker and date.\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"ticker\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"The stock ticker symbol, e.g., \\\\\"IBM\\\\\".\"\\n                },\\n                \"date\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"The date in \\\\\"YYYY-MM-DD\\\\\" format for which you want to get stock prices.\"\\n                }\\n            },\\n            \"required\": [\\n                \"ticker\",\\n                \"date\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"A dictionary containing the low and high stock prices on the given date.\"\\n        }\\n    },\\n    {\\n        \"name\": \"get_current_weather\",\\n        \"description\": \"Fetches the current weather for a given location (default: San Francisco).\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"location\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"The name of the city for which to retrieve the weather information.\"\\n                }\\n            },\\n            \"required\": [\\n                \"location\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"A dictionary containing weather information such as temperature, weather description, and humidity.\"\\n        }\\n    }\\n]<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>What is the current weather in San Francisco?<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"system\",\"content\": \"You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.\"},\n",
    "    {\"role\": \"user\", \"content\": query },\n",
    "]\n",
    "\n",
    "instruction_1 = TOKENIZER.apply_chat_template(conversation=conversation, tools=tools, tokenize=False, add_generation_prompt=True)\n",
    "instruction_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|start_of_role|>system<|end_of_role|>You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.<|end_of_text|>\\n<|start_of_role|>tools<|end_of_role|>[\\n    {\\n        \"name\": \"get_stock_price_ja\",\\n        \"description\": \"指定されたティッカーと日付の最安値と最高値を取得します。\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"ticker\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"株券のティッカーシンボル、例えば 「IBM」。\"\\n                },\\n                \"date\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"株価を取得したい日付を「YYYY-MM-DD」形式で指定します。\"\\n                }\\n            },\\n            \"required\": [\\n                \"ticker\",\\n                \"date\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"指定された日付の株価の安値と高値を含む辞書。\"\\n        }\\n    },\\n    {\\n        \"name\": \"get_current_weather_ja\",\\n        \"description\": \"指定した場所（デフォルト：サンフランシスコ）の現在の天気を取得します。\",\\n        \"parameters\": {\\n            \"type\": \"object\",\\n            \"properties\": {\\n                \"location\": {\\n                    \"type\": \"string\",\\n                    \"description\": \"気象情報を取得する都市名。\"\\n                }\\n            },\\n            \"required\": [\\n                \"location\"\\n            ]\\n        },\\n        \"return\": {\\n            \"type\": \"object\",\\n            \"description\": \"気温、天気予報、湿度などの気象情報を含む辞書。\"\\n        }\\n    }\\n]<|end_of_text|>\\n<|start_of_role|>user<|end_of_role|>サンフランシスコの現在の天気は？<|end_of_text|>\\n<|start_of_role|>assistant<|end_of_role|>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_ja = [\n",
    "    {\"role\": \"system\",\"content\": \"You are a helpful assistant with access to the following function calls. Your task is to produce a list of function calls necessary to generate response to the user utterance. Use the following function calls as required.\"},\n",
    "    {\"role\": \"user\", \"content\": query_ja },\n",
    "]\n",
    "\n",
    "instruction_1_ja = TOKENIZER.apply_chat_template(conversation=conversation_ja, tools=tools_ja, tokenize=False, add_generation_prompt=True)\n",
    "instruction_1_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tool_call>[{\"name\": \"get_current_weather\", \"arguments\": {\"location\": \"San Francisco\"}}]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = make_api_request(instruction_1)\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tool_call>[{\"name\": \"get_current_weather_ja\", \"arguments\": {\"location\": \"サンフランシスコ\"}}]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_ja = make_api_request(instruction_1_ja)\n",
    "data_1_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the model decides the appropriate tool choice, in this case `get_current_weather`, and extracts the location correctly. Now, let's call the function with the argument generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather for San Francisco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'broken clouds', 'temperature': 12.29, 'humidity': 83}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response = tool_call(data_1)\n",
    "tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting current weather for サンフランシスコ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'broken clouds', 'temperature': 12.29, 'humidity': 83}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response_ja = tool_call(data_1_ja)\n",
    "tool_response_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function response correctly describes the current weather in San Francisco. Lastly, let's generate a synthesized final response with the results of this function call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is broken clouds with a temperature of 12.29 degrees and a humidity level of 83%.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2 = conversation + [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Display the tool response in natural language.\" },\n",
    "    {\"role\": \"tool_response\", \"content\": str(tool_response) },\n",
    "]\n",
    "\n",
    "instruction_2 = TOKENIZER.apply_chat_template(conversation=conversation2, tools=tools, tokenize=False, add_generation_prompt=True)\n",
    "data_2 = make_api_request(instruction_2)\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'現在、サンフランシスコの天気は、部分的に雲がかかっています。気温は12.29度で、湿度は83%です。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation2_ja = conversation_ja + [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Display the tool response in natural language.\" },\n",
    "    {\"role\": \"tool_response\", \"content\": str(tool_response_ja) },\n",
    "]\n",
    "\n",
    "instruction_2_ja = TOKENIZER.apply_chat_template(conversation=conversation2_ja, tools=tools_ja, tokenize=False, add_generation_prompt=True)\n",
    "data_2_ja = make_api_request(instruction_2_ja)\n",
    "data_2_ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you built custom functions and used the Granite-3-8B-Instruct model to determine which function to call based on  key information from user queries. With this information, you called the function with the arguments as stated in the model response. These function calls produce the expected output. Finally, you called the Granite-3-8B-Instruct model again to synthesize the information returned by the functions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "granite-snack-cookbook-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
